{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot_Using_Multilayer_Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertechnician/Chatbot-using-ANN/blob/main/Chatbot_Using_Multilayer_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjp0jNQlh4nz"
      },
      "source": [
        " # Chatbot based on Bag Of Words Model using Multilayer Perceptron\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n2ECf67BpMz"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import json\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import nltk\r\n",
        "import random\r\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK2ewH91U93U"
      },
      "source": [
        "## Install `optuna`\n",
        "\n",
        "Optuna can be installed via `pip` or `conda`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnAFRi_YU93X"
      },
      "source": [
        "!pip install --quiet optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WYasAKlU93X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e712677-37f4-49ed-b528-ddeff6a29d4d"
      },
      "source": [
        "import optuna\n",
        "\n",
        "optuna.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_4nd3lOEcqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0123dd9-ec67-4869-8609-62a6f31c4466"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VL_BOt4BpM0"
      },
      "source": [
        "corpus_name = \"Institution-bag of words\"\n",
        "corpus = os.path.join(\"/content/drive/My Drive/Colab Notebooks/data\", corpus_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOm9PFrT8mGG"
      },
      "source": [
        "# NLTK Utilities\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwu_sWHv4jEo",
        "outputId": "9ff3fceb-f07a-41ee-8545-46c2e8f2dc1b"
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "stemmer = PorterStemmer()\r\n",
        "print(\"HELLO\")\r\n",
        "def tokenize(sentence):\r\n",
        "  return nltk.word_tokenize(sentence)\r\n",
        "\r\n",
        "def stem(word):\r\n",
        "  return stemmer.stem(word.lower())\r\n",
        "\r\n",
        "def bag_of_words(tokenized_sentence, words):\r\n",
        "    # stem each word\r\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\r\n",
        "    # initialize bag with 0 for each word\r\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\r\n",
        "    for idx, w in enumerate(words):\r\n",
        "        if w in sentence_words: \r\n",
        "            bag[idx] = 1\r\n",
        "\r\n",
        "    return bag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "HELLO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GATla7PypCFH"
      },
      "source": [
        " # Model\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d0xJz3VzLOo"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9q0pp33dckN"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXF0_gNCRH08",
        "outputId": "e9ec46cc-7422-4438-ef09-a743f4fd8954"
      },
      "source": [
        "# make it true to tune the hyperparameters using Optuna tuning method\r\n",
        "tuning=False\r\n",
        "\r\n",
        "with open(os.path.join(corpus, \"intents.json\"), 'r') as f:\r\n",
        "    intents = json.load(f)\r\n",
        "\r\n",
        "all_words = []\r\n",
        "tags = []\r\n",
        "xy = []\r\n",
        "# loop through each sentence in our intents patterns\r\n",
        "for intent in intents['intents']:\r\n",
        "    tag = intent['tag']\r\n",
        "    # add to tag list\r\n",
        "    tags.append(tag)\r\n",
        "    for pattern in intent['patterns']:\r\n",
        "        # tokenize each word in the sentence\r\n",
        "        w = tokenize(pattern)\r\n",
        "        # add to our words list\r\n",
        "        all_words.extend(w)\r\n",
        "        # add to xy pair\r\n",
        "        xy.append((w, tag))\r\n",
        "\r\n",
        "# stem and lower each word\r\n",
        "ignore_words = ['?', '.', '!']\r\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\r\n",
        "# remove duplicates and sort\r\n",
        "all_words = sorted(set(all_words))\r\n",
        "tags = sorted(set(tags))\r\n",
        "\r\n",
        "print(len(xy), \"patterns\")\r\n",
        "print(len(tags), \"tags:\", tags)\r\n",
        "print(len(all_words), \"unique stemmed words:\", all_words)\r\n",
        "\r\n",
        "# create training data\r\n",
        "X_train = []\r\n",
        "y_train = []\r\n",
        "for (pattern_sentence, tag) in xy:\r\n",
        "    # X: bag of words for each pattern_sentence\r\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\r\n",
        "    X_train.append(bag)\r\n",
        "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\r\n",
        "    label = tags.index(tag)\r\n",
        "    y_train.append(label)\r\n",
        "\r\n",
        "X_train = np.array(X_train)\r\n",
        "y_train = np.array(y_train)\r\n",
        "\r\n",
        "# Hyper-parameters\r\n",
        "num_workers = 0\r\n",
        "num_epochs = 1000\r\n",
        "batch_size = 8\r\n",
        "learning_rate = 0.001\r\n",
        "input_size = len(X_train[0])\r\n",
        "hidden_size = 8\r\n",
        "output_size = len(tags)\r\n",
        "print(input_size, output_size)\r\n",
        "\r\n",
        "class ChatDataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        self.n_samples = len(X_train)\r\n",
        "        self.x_data = X_train\r\n",
        "        self.y_data = y_train\r\n",
        "\r\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\r\n",
        "    def __getitem__(self, index):\r\n",
        "        return self.x_data[index], self.y_data[index]\r\n",
        "\r\n",
        "    # we can call len(dataset) to return the size\r\n",
        "    def __len__(self):\r\n",
        "        return self.n_samples \r\n",
        "\r\n",
        "dataset = ChatDataset()\r\n",
        "train_loader = DataLoader(dataset=dataset,\r\n",
        "                          batch_size=batch_size,\r\n",
        "                          shuffle=True,\r\n",
        "                          num_workers=num_workers)\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\r\n",
        "\r\n",
        "# Loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "\r\n",
        "# Train the model\r\n",
        "def run_training( ):\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        for (words, labels) in train_loader:\r\n",
        "            words = words.to(device)\r\n",
        "            labels = labels.to(dtype=torch.long).to(device)\r\n",
        "\r\n",
        "            # Forward pass\r\n",
        "            outputs = model(words)\r\n",
        "            # if y would be one-hot, we must apply\r\n",
        "            # labels = torch.max(labels, 1)[1]\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "            # Backward and optimize\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "        if (epoch+1) % 100 == 0:\r\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\r\n",
        "\r\n",
        "    print(f'final loss: {loss.item():.4f}')\r\n",
        "    return loss.item()\r\n",
        "\r\n",
        "# Train the model for tuning hyperparameters\r\n",
        "def run_training_for_tuning(params):\r\n",
        "\r\n",
        "    # Hyper-parameters\r\n",
        "    num_workers = params[\"num_workers\"]\r\n",
        "    batch_size = params[\"batch_size\"]\r\n",
        "    learning_rate = params[\"learning_rate\"]\r\n",
        "    hidden_size = params[\"hidden_size\"]\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        for (words, labels) in train_loader:\r\n",
        "            words = words.to(device)\r\n",
        "            labels = labels.to(dtype=torch.long).to(device)\r\n",
        "\r\n",
        "            # Forward pass\r\n",
        "            outputs = model(words)\r\n",
        "            # if y would be one-hot, we must apply\r\n",
        "            # labels = torch.max(labels, 1)[1]\r\n",
        "            loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "            # Backward and optimize\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "        if (epoch+1) % 100 == 0:\r\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\r\n",
        "\r\n",
        "    print(f'final loss: {loss.item():.4f}')\r\n",
        "    return loss.item()\r\n",
        "\r\n",
        "\r\n",
        "def objective(trial):\r\n",
        "    params = {\r\n",
        "        \"num_workers\": trial.suggest_int(\"num_workers\", 0, 2),\r\n",
        "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 300, 1200),\r\n",
        "        \"batch_size\": trial.suggest_int(\"batch_size\", 5, 10),\r\n",
        "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3)\r\n",
        "    }\r\n",
        "    all_losses = []\r\n",
        "    for f in range(2):\r\n",
        "        temp_loss = run_training_for_tuning(params)\r\n",
        "        all_losses.append(temp_loss)\r\n",
        "\r\n",
        "    return np.mean(all_losses)\r\n",
        "\r\n",
        "\r\n",
        "if tuning==True:\r\n",
        "  if __name__ == \"__main__\":\r\n",
        "      tuning = optuna.create_study(direction=\"minimize\")\r\n",
        "      tuning.optimize(objective, n_trials=3)\r\n",
        "\r\n",
        "      print(\"best trial:\")\r\n",
        "      trial_ = tuning.best_trial\r\n",
        "\r\n",
        "      print(trial_.values)\r\n",
        "      print(trial_.params)\r\n",
        "\r\n",
        "      scores = 0\r\n",
        "      for j in range(1):\r\n",
        "          scr = run_training(j, trial_.params, save_model=true)\r\n",
        "          scores += scr\r\n",
        "      print(scores)\r\n",
        "else:\r\n",
        "  run_training()\r\n",
        "\r\n",
        "data = {\r\n",
        "    \"model_state\": model.state_dict(),\r\n",
        "    \"input_size\": input_size,\r\n",
        "    \"hidden_size\": hidden_size,\r\n",
        "    \"output_size\": output_size,\r\n",
        "    \"all_words\": all_words,\r\n",
        "    \"tags\": tags\r\n",
        "}\r\n",
        "\r\n",
        "# FILE = \"data.pth\"\r\n",
        "FILE =os.path.join(corpus, \"data.pth\")\r\n",
        " \r\n",
        "torch.save(data, FILE)\r\n",
        "\r\n",
        "print(f'training complete. file saved to {FILE}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56 patterns\n",
            "11 tags: ['College', 'Course', 'Department', 'Module', 'Student', 'Teacher', 'funny', 'goodbye', 'greeting', 'payments', 'thanks']\n",
            "81 unique stemmed words: [\"'s\", 'a', 'accept', 'am', 'anyon', 'applic', 'are', 'belong', 'branch', 'bye', 'can', 'card', 'cash', 'centr', 'chatbot', 'colleg', 'cours', 'credit', 'day', 'degre', 'depart', 'do', 'doe', 'educ', 'enrol', 'for', 'funni', 'good', 'goodby', 'guid', 'ha', 'he', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'institu', 'instructor', 'is', 'joke', 'know', 'later', 'lectur', 'lot', 'made', 'mastercard', 'me', 'modul', 'name', 'of', 'onli', 'pay', 'paypal', 'professor', 'see', 'someth', 'stream', 'student', 'studi', 'subdivis', 'subject', 'take', 'task', 'teacher', 'tell', 'thank', 'that', 'the', 'there', 'thi', 'unit', 'univers', 'user', 'what', 'where', 'which', 'who', 'with', 'you']\n",
            "81 11\n",
            "Epoch [100/1000], Loss: 1.0251\n",
            "Epoch [200/1000], Loss: 0.1961\n",
            "Epoch [300/1000], Loss: 0.0102\n",
            "Epoch [400/1000], Loss: 0.0042\n",
            "Epoch [500/1000], Loss: 0.0037\n",
            "Epoch [600/1000], Loss: 0.0950\n",
            "Epoch [700/1000], Loss: 0.0012\n",
            "Epoch [800/1000], Loss: 0.0006\n",
            "Epoch [900/1000], Loss: 0.0004\n",
            "Epoch [1000/1000], Loss: 0.0003\n",
            "final loss: 0.0003\n",
            "training complete. file saved to /content/drive/My Drive/Colab Notebooks/data/Institution-bag of words/data.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDji4LSKqj8W"
      },
      "source": [
        "# Chat\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiJVCmu3dhFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587badda-dbe1-45c6-ab1a-6636ead1fccc"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with open(os.path.join(corpus, \"intents.json\"), 'r') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "# FILE = \"data.pth\"\n",
        "FILE =os.path.join(corpus, \"data.pth\")\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n",
        "\n",
        "bot_name = \"Guide\"\n",
        "print(\"Welcome to DMU! (type 'quit' to exit)\"+\"\\n\")\n",
        "print(\"I am your guide\"+\"\\n\")\n",
        "print(\"You can ask me questions about the details of the student.\"+\"\\n\")\n",
        "print(\"Type 'quit' to exit\"+\"\\n\")\n",
        "while True:\n",
        "    # sentence = \"do you use credit cards?\"\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"quit\":\n",
        "        break\n",
        "\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.75:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\"+\"\\n\")\n",
        "    else:\n",
        "        print(f\"{bot_name}:Can you be more specific, please!\"+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to DMU! (type 'quit' to exit)\n",
            "\n",
            "I am your guide\n",
            "\n",
            "You can ask me questions about the details of the student.\n",
            "\n",
            "Type 'quit' to exit\n",
            "\n",
            "You: Hi\n",
            "Guide: Hi there, what can I do for you?\n",
            "\n",
            "You: What is the name of the student?\n",
            "Guide: Arpit Sharma is the name of the student\n",
            "\n",
            "You: Who is the student?\n",
            "Guide: The student's name is Arpit Sharma\n",
            "\n",
            "You: student name?\n",
            "Guide: The student's name is Arpit Sharma\n",
            "\n",
            "You: name of the student?\n",
            "Guide: Arpit Sharma\n",
            "\n",
            "You: What is the name of the department?\n",
            "Guide: The course belongs to the centre for Computational Intelligence\n",
            "\n",
            "You: branch?\n",
            "Guide: The course belongs to the CCI department\n",
            "\n",
            "You: What is the name of the college?\n",
            "Guide: He/She is a student at De Montfort University,Leicester\n",
            "\n",
            "You: What is the name of the university?\n",
            "Guide: He/She is a student at De Montfort University,Leicester\n",
            "\n",
            "You: Which course is he studying?\n",
            "Guide:  The student is studying intelligent systems and robotics, MSc\n",
            "\n",
            "You: module name?\n",
            "Guide: The student is studying NLP\n",
            "\n",
            "You: Who is the teacher?\n",
            "Guide: Dr.Aboozar Taherkhani is the teacher of this module\n",
            "\n",
            "You: When is the next football match? \n",
            "Guide:Can you be more specific, please!\n",
            "\n",
            "You: Bye\n",
            "Guide: Bye! Come back again soon.\n",
            "\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}